{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc4b10-9577-4ee7-8a2d-1a708e78ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Force CPU usage to avoid CUDA compatibility issues\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Clear session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('star_wars_dataset.csv')\n",
    "print(f\"Dataset loaded with {len(df)} rows\")\n",
    "\n",
    "# Clean data\n",
    "df = df.dropna()\n",
    "df = df[df['pattern'].str.strip() != '']\n",
    "print(f\"After cleaning: {len(df)} rows\")\n",
    "\n",
    "# Let's see what data we have\n",
    "print(\"\\nSample of your data:\")\n",
    "print(df.head())\n",
    "\n",
    "patterns = df['pattern'].tolist()\n",
    "intents = df['intent'].tolist()\n",
    "\n",
    "# Tokenization - let's use a smaller vocabulary\n",
    "tokenizer = Tokenizer(num_words=50, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(patterns)\n",
    "sequences = tokenizer.texts_to_sequences(patterns)\n",
    "max_length = max(len(seq) for seq in sequences) if sequences else 10\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "print(f\"\\nVocabulary size: {len(tokenizer.word_index)}\")\n",
    "print(f\"Max sequence length: {max_length}\")\n",
    "print(f\"Sample sequences: {sequences[:3]}\")\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(intents)\n",
    "print(f\"Number of intents: {len(le.classes_)}\")\n",
    "print(f\"Intents: {le.classes_}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "\n",
    "# Simple RNN Model - simplified for small dataset\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=50,  # Use num_words instead of full vocabulary\n",
    "        output_dim=8,  # Smaller embedding\n",
    "        input_length=max_length\n",
    "    ),\n",
    "    tf.keras.layers.SimpleRNN(16, return_sequences=False),  # Smaller RNN\n",
    "    tf.keras.layers.Dense(12, activation='relu'),  # Smaller dense layer\n",
    "    tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model with more epochs\n",
    "print(\"Starting Simple RNN training on CPU...\")\n",
    "history = model.fit(\n",
    "    padded_sequences, \n",
    "    labels, \n",
    "    epochs=200,  # More epochs for small dataset\n",
    "    batch_size=2,  # Smaller batch size\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Simple RNN training completed successfully!\")\n",
    "\n",
    "# Let's check the training accuracy\n",
    "train_loss, train_acc = model.evaluate(padded_sequences, labels, verbose=0)\n",
    "print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "\n",
    "def chatbot_response(text):\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    print(f\"Input: '{text}' -> Sequence: {seq}\")  # Debug info\n",
    "    \n",
    "    if not seq or len(seq[0]) == 0:\n",
    "        return \"I'm not sure how to respond to that.\"\n",
    "    \n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "    pred = model.predict(padded, verbose=0)\n",
    "    intent_index = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "    \n",
    "    print(f\"Prediction: {pred}, Max confidence: {confidence:.4f}\")  # Debug info\n",
    "    \n",
    "    intent_tag = le.inverse_transform([intent_index])[0]\n",
    "    print(f\"Predicted intent: {intent_tag}\")  # Debug info\n",
    "\n",
    "    resp_list = df[df['intent']==intent_tag]['response'].tolist()\n",
    "    \n",
    "    # Lower confidence threshold for small dataset\n",
    "    if confidence < 0.3:  # Much lower threshold\n",
    "        return f\"I'm not sure about that (confidence: {confidence:.2f}). Could you ask something else about Star Wars?\"\n",
    "    \n",
    "    return np.random.choice(resp_list) if resp_list else \"I don't have a response for that.\"\n",
    "\n",
    "# Test the Simple RNN chatbot with exact pattern matches first\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING WITH EXACT PATTERNS FROM DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test with exact patterns from your dataset\n",
    "for pattern in df['pattern'].head(5):\n",
    "    response = chatbot_response(pattern)\n",
    "    print(f\"\\nQ: {pattern}\")\n",
    "    print(f\"A: {response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING WITH SIMILAR QUESTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test with similar questions\n",
    "test_questions = [\n",
    "    \"Who is Luke Skywalker?\",\n",
    "    \"Tell me about the Force\",\n",
    "    \"What is a lightsaber?\",\n",
    "    \"Who is Darth Vader?\",\n",
    "    \"What is the Millennium Falcon?\",\n",
    "    \"Tell me about Jedi\",\n",
    "    \"Hello\",\n",
    "    \"What can you do?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    response = chatbot_response(question)\n",
    "    print(f\"\\n{i}. Q: {question}\")\n",
    "    print(f\"   A: {response}\")\n",
    "\n",
    "# Let's also see what the model predicts for all training data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING TRAINING DATA PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, (pattern, intent) in enumerate(zip(patterns, intents), 1):\n",
    "    seq = tokenizer.texts_to_sequences([pattern])\n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "    pred = model.predict(padded, verbose=0)\n",
    "    predicted_intent = le.inverse_transform([np.argmax(pred)])[0]\n",
    "    confidence = np.max(pred)\n",
    "    \n",
    "    status = \"✓\" if predicted_intent == intent else \"✗\"\n",
    "    print(f\"{i}. {status} Pattern: '{pattern}' -> Actual: {intent}, Predicted: {predicted_intent}, Confidence: {confidence:.4f}\")\n",
    "\n",
    "# Interactive mode\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INTERACTIVE MODE - Type 'quit' to exit\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nYou: \").strip()\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        print(\"Chatbot: May the Force be with you!\")\n",
    "        break\n",
    "    response = chatbot_response(user_input)\n",
    "    print(f\"Chatbot: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02612353-c088-414a-926b-ae063d999e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Analysis:\n",
      "Total samples: 139\n",
      "Number of unique intents: 10\n",
      "\n",
      "Samples per intent:\n",
      "intent\n",
      "ask_character             74\n",
      "ask_concept               30\n",
      "feedback                   6\n",
      "try                        6\n",
      "movie                      6\n",
      "farewell                   4\n",
      "question                   4\n",
      "greeting                   3\n",
      "doubt                      3\n",
      "ask_character_relation     3\n",
      "Name: count, dtype: int64\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-09-16 19:54:51.477070: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: JIT compilation failed.\n",
      "2025-09-16 19:54:51.477104: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: UNKNOWN: JIT compilation failed.\n",
      "\t [[{{node sequential_3/lstm_4/lstm_cell/recurrent_kernel/Initializer/Sign}}]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_3/lstm_4/lstm_cell/recurrent_kernel/Initializer/Sign defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_9172/1871666515.py\", line 65, in <module>\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nJIT compilation failed.\n\t [[{{node sequential_3/lstm_4/lstm_cell/recurrent_kernel/Initializer/Sign}}]] [Op:__inference_initialize_variables_9190]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 65\u001b[0m\n\u001b[1;32m     58\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     59\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     60\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     61\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     66\u001b[0m     X_train, y_train,\n\u001b[1;32m     67\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     68\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     69\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[1;32m     70\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m     74\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstar_wars_rnn_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:132\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mOptional\u001b[38;5;241m.\u001b[39mfrom_value(\n\u001b[0;32m--> 132\u001b[0m             one_step_on_data(iterator\u001b[38;5;241m.\u001b[39mget_next())\n\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     empty_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mOptional\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node sequential_3/lstm_4/lstm_cell/recurrent_kernel/Initializer/Sign defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipykernel_9172/1871666515.py\", line 65, in <module>\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/gabriel/miniconda3/envs/am/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nJIT compilation failed.\n\t [[{{node sequential_3/lstm_4/lstm_cell/recurrent_kernel/Initializer/Sign}}]] [Op:__inference_initialize_variables_9190]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pickle\n",
    "\n",
    "# Load your improved dataset\n",
    "df = pd.read_csv('star_wars_dataset.csv')\n",
    "\n",
    "# Analyze the final dataset\n",
    "print(\"Final Dataset Analysis:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Number of unique intents: {df['intent'].nunique()}\")\n",
    "print(\"\\nSamples per intent:\")\n",
    "print(df['intent'].value_counts())\n",
    "\n",
    "# Preprocess data\n",
    "texts = df['pattern'].values\n",
    "labels = df['intent'].values\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "num_classes = len(np.unique(encoded_labels))\n",
    "categorical_labels = to_categorical(encoded_labels, num_classes=num_classes)\n",
    "\n",
    "# Split data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    padded_sequences, categorical_labels, \n",
    "    test_size=0.2, random_state=42, stratify=encoded_labels\n",
    ")\n",
    "\n",
    "# Build RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=max_length))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save model\n",
    "model.save('star_wars_rnn_model.h5')\n",
    "\n",
    "# Save preprocessing objects\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "class_names = label_encoder.classes_\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
